name: FDP Pipeline

on:
  push:
    branches:
      - main
  pull_request:

jobs:
  build-test-deploy:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout your repo
      - name: Checkout repo
        uses: actions/checkout@v3

      # Step 2: Set up Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11.9'

      # Step 3: Install dependencies
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest

      # ðŸ‘‰ Step 3.5: Make pipeline importable
      - name: Set PYTHONPATH
        run: echo "PYTHONPATH=$PWD" >> $GITHUB_ENV

      # Step 4: Run tests
      - name: Run tests
        run: |
          pytest tests/test_dag_validation.py

      # Step 5: Validate Airflow DAGs
      - name: Validate DAGs
        run: |
          python -c "from airflow.models import DagBag; DagBag().dagbag_stats"

      # Step 6: Deploy DAGs to S3
      - name: Deploy DAGs to S3
        run: |
          aws s3 cp ./dags s3://fraud-detection-data-ameer/dags/ --recursive
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}